from aiohttp import web, ClientSession
import asyncio
import json
from bs4 import BeautifulSoup
from datetime import datetime, time as dt_time, timedelta
import aiofiles

# URL trang web cáº§n láº¥y dá»¯ liá»‡u
URL = "https://ketqua.me/xsmb-xo-so-mien-bac"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}
RESULT_FILE = "result.json"  # File lÆ°u trá»¯ káº¿t quáº£

async def load_latest_data():
    """Äá»c dá»¯ liá»‡u tá»« file result.json"""
    try:
        async with aiofiles.open(RESULT_FILE, mode='r', encoding='utf-8') as f:
            content = await f.read()
            return json.loads(content)
    except (FileNotFoundError, json.JSONDecodeError):
        return {"date": "", "results": {}}

async def save_latest_data(data):
    """LÆ°u dá»¯ liá»‡u vÃ o file result.json"""
    async with aiofiles.open(RESULT_FILE, mode='w', encoding='utf-8') as f:
        await f.write(json.dumps(data, ensure_ascii=False, indent=4))

async def fetch_data():
    """HÃ m táº£i dá»¯ liá»‡u tá»« trang web"""
    async with ClientSession() as session:
        try:
            async with session.get(URL, headers=HEADERS) as response:
                response.raise_for_status()
                html = await response.text()
                soup = BeautifulSoup(html, "html.parser")

                # Láº¥y ngÃ y xá»• sá»‘
                date_text = ""
                date_div = soup.find("div", class_="title-link-item mb_date_info")
                if date_div:
                    date_links = date_div.find_all("a")
                    if len(date_links) > 2:
                        date_text = date_links[2].text.strip()

                # Láº¥y káº¿t quáº£ xá»• sá»‘
                result_table = soup.find("table", id="table-22")
                results = {}

                if result_table:
                    for row in result_table.find_all("tr"):
                        cells = row.find_all(["th", "td"])
                        cell_values = [cell.text.strip() for cell in cells]

                        if cell_values and cell_values[0]:  # Bá» qua hÃ ng rá»—ng
                            results[cell_values[0]] = cell_values[1:]

                # Cáº­p nháº­t vÃ  lÆ°u dá»¯ liá»‡u
                latest_data = {"date": date_text, "results": results}
                await save_latest_data(latest_data)
                print(f"âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t vÃ o {datetime.now()}!")
        except Exception as e:
            print(f"âŒ Lá»—i khi fetch dá»¯ liá»‡u: {e}")

async def wait_until_next_update():
    """Chá» Ä‘áº¿n 18h45 má»—i ngÃ y Ä‘á»ƒ cáº­p nháº­t dá»¯ liá»‡u"""
    while True:
        now = datetime.now()
        next_update_time = datetime.combine(now.date(), dt_time(18, 45))  # Cáº­p nháº­t lÃºc 18h45
        
        if now >= next_update_time:  # Náº¿u Ä‘Ã£ qua 18h45, chá» Ä‘áº¿n 18h45 ngÃ y mai
            next_update_time += timedelta(days=1)

        sleep_seconds = (next_update_time - now).total_seconds()
        print(f"ğŸ•’ Chá» {sleep_seconds / 3600:.2f} giá» Ä‘áº¿n láº§n cáº­p nháº­t tiáº¿p theo ({next_update_time})")

        await asyncio.sleep(sleep_seconds)  # Äá»£i Ä‘áº¿n thá»i Ä‘iá»ƒm cáº§n cáº­p nháº­t
        await fetch_data()  # Cáº­p nháº­t dá»¯ liá»‡u

async def get_date(request):
    """API tráº£ vá» ngÃ y xá»• sá»‘"""
    latest_data = await load_latest_data()
    return web.json_response({"date": latest_data["date"]})

async def get_results(request):
    """API tráº£ vá» káº¿t quáº£ xá»• sá»‘"""
    latest_data = await load_latest_data()
    return web.json_response(latest_data["results"])

app = web.Application()
app.router.add_get('/xsmb/get_date', get_date)
app.router.add_get('/xsmb/get_results', get_results)

# Khá»Ÿi Ä‘á»™ng background task khi server cháº¡y
async def on_startup(app):
    asyncio.create_task(wait_until_next_update())

app.on_startup.append(on_startup)

if __name__ == '__main__':
    web.run_app(app, host='0.0.0.0', port=10000)
